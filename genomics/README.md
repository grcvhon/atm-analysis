# Integrating genomics in species distribution modelling
<br>
This directory contains scripts for genomic analyses as part of species distribution modelling.<br>
<br>
The idea here is to develop ancestry probability maps or calculate genetic distances which will be used to generate a raster layer that will inform the species distribution model.<br>
<br>
This README file is quite detailed as I treat it as a logbook to keep track of what I am doing in the command line.<br>
<br>
<i>NB: Data used are stored in the Phoenix HPC (University of Adelaide).</i>

<br>
<br>

## Outline

- [Prepare sample sheet of <i>Aipysurus apraefrontalis</i> and <i>A. foliosquama</i> individuals with RADseq data](#prepare-sample-sheet-of-aipysurus-apraefrontalis-and-a-foliosquama-individuals-with-radseq-data)
- [On kraken2 and UniVec databases](#on-kraken2-and-univec-databases)
- [Running ipyrad](#running-ipyrad)
- [Running API: ipyrad analysis tools](#running-api-ipyrad-analysis-tools)

---

### Prepare sample sheet of <i>Aipysurus apraefrontalis</i> and <i>A. foliosquama</i> individuals with RADseq data

This step involves collating information regarding samples of <i>Aipysurus apraefrontalis</i> and <i>A. foliosquama</i> that have available RADseq data (i.e., stored in `PhoenixHPC:/uofaresstor/sanders_lab/`). These data were generated by DArT (https://diversityarrays.com) and so the frequent use of DArT/DArTseq in this document.<br>

The goal of this collation is to generate a sample sheet that has at least the following information: `order`,`dart_id`,`id_clean` (for an example, see https://github.com/a-lud/sea-snake-dart/blob/main/data/sample-sheets/240524-sample-linkage.csv).<br>

* `order` corresponds to the DArT order number (`DNote##-####`)
* `dart_id` corresponds to the `.FASTQ.gz` prefix
* `id_clean` for example, <i>Hydrophis major</i> with KLS 1010 and FASTQ prefix 1234567: `HMA-KLS1010-1234567` (no whitespaces)
* `barcode9l`
* `barcode`

This format will improve efficiency when processing samples prior to any analyses and when using the workflow in genomics analyses.<br>

<i>NB: Scripts were not used entirely to collate information and some manual manipulation is required (e.g., via MS Excel).</i><br>

#### 1) Extract information from DArTseq master spreadsheet
First, we refer to the file: `DARTseq_master.xlsx` (version as of 11 February 2025). We then filter, in MS Excel, for <i>A. apraefrontalis</i> and <i>A. foliosquama</i>. Take note of some of the comments as some samples may have been contaminated or of just low quality. Nonetheless, we take all rows that are either <i>A. apraefrontalis</i> or <i>A. foliosquama</i>.<br>

We also added columns to contain information on latitude and longitude (if present, obtained from `The_One_Spreadsheet` and other field data sheets; files not stored in this repo), and if sample is usable (yes/no) based on information from `DARTseq_master.xlsx`.<br>

This spreadsheet was assembled manually and output is shown below (first 10 entries):

|Source                  |SampleID      |Genus    |Species       |Location    |Latitude    |Longitude  |DaRT_set    |FASTQ.gz|Comments                             |Use|
|------------------------|--------------|---------|--------------|------------|------------|-----------|------------|--------|-------------------------------------|---|
|PreATM_sampling         |Aaprae 4.12.01|Aipysurus|apraefrontalis|Ashmore Reef|-12.24174549|123.04166  |DNote21-6332|2562202 |Coordinates approximate              |yes|
|PreATM_sampling         |KLS0834       |Aipysurus|apraefrontalis|Exmouth Gulf|-22.166666  |114.2999988|DNote21-6332|2562130 |Coordinates approximate              |yes|
|PreATM_sampling         |SAM R68142    |Aipysurus|apraefrontalis|            |            |           |DNote21-6332|2571051 |Low quality DaRT                     |no |
|PreATM_sampling         |SS171013-03   |Aipysurus|apraefrontalis|Pilbara     |-19.6889305 |118.220874 |DNote21-6332|2562139 |                                     |yes|
|PreATM_sampling         |Afo1          |Aipysurus|foliosquama   |Ashmore Reef|-12.24174549|123.04166  |DNote21-6332|2562140 |Coordinates approximate              |yes|
|PreATM_sampling         |Afo8          |Aipysurus|foliosquama   |Ashmore Reef|-12.24174549|123.04166  |DNote21-6332|2562249 |Coordinates approximate              |yes|
|PreATM_sampling         |Afo8          |Aipysurus|foliosquama   |Ashmore Reef|-12.24174549|123.04166  |DNote21-6332|2571080 |Coordinates approximate              |yes|
|PreATM_sampling         |KLS1001       |Aipysurus|foliosquama   |            |            |           |DNote21-6332|2562209 |WA Coast apraefrontalis_contamination|no |
|PreATM_sampling         |KLS1001       |Aipysurus|foliosquama   |            |            |           |DNote21-6332|2584016 |WA Coast apraefrontalis_contamination|no |

<i>NB: For complete output, see: </i>`atm_genetic_dataset.csv`.
<br>

#### 2) Use command line to initialise our sample sheet file
From our `atm_genetic_dataset.csv` file, we want to initialise the first 3 columns of our sample sheet in the desired format. Using the following command, let us extract the samples that have a "yes" (i.e., usable) in the `Use` column of our `atm_genetic_dataset.csv`.
<br>
```bash
awk -F, '{ if ( $11 ~ /yes/ ) { print $2, $3, $4, $9, $11 } }' atm_genetic_dataset.csv
```
This command goes: if column 11 (`Use`) is "yes", print out information for these columns: `SampleID`, `Genus`, `Species`, `FASTQ.gz`, `Use`<br>
```
# output
Aaprae 4.12.01 Aipysurus apraefrontalis 2562202 yes
KLS0834 Aipysurus apraefrontalis 2562130 yes
SS171013-03 Aipysurus apraefrontalis 2562139 yes
Afo1 Aipysurus foliosquama 2562140 yes
Afo8 Aipysurus foliosquama 2562249 yes
Afo8 Aipysurus foliosquama 2571080 yes
SS171014-02 Aipysurus foliosquama 2562167 yes
KLS1484 Aipysurus apraefrontalis 3517861 yes
KLS1486 Aipysurus apraefrontalis 3517868 yes
KLS1490 Aipysurus apraefrontalis 3517879 yes
KLS1435 Aipysurus apraefrontalis 3593375 yes
KLS1436 Aipysurus apraefrontalis 3593362 yes
KLS1454 Aipysurus apraefrontalis 3593372 yes
KLS1457 Aipysurus apraefrontalis 3593394 yes
KLS1459 Aipysurus apraefrontalis 3593395 yes
KLS1465 Aipysurus apraefrontalis 3593393 yes
KLS1468 Aipysurus apraefrontalis 3593397 yes
KLS1477 Aipysurus apraefrontalis 3593356 yes
KLS1509 Aipysurus apraefrontalis 3593337 yes
KLS1202 Aipysurus foliosquama 3593377 yes
KLS1696 Aipysurus foliosquama 4013436 yes
KLS1700 Aipysurus foliosquama 4013440 yes
KLS1701 Aipysurus foliosquama 4013441 yes
KLS1702 Aipysurus foliosquama 4013442 yes
KLS1707 Aipysurus foliosquama 4013447 yes
KLS1708 Aipysurus foliosquama 4013448 yes
KLS1710 Aipysurus foliosquama 4013450 yes
```
Knowing that the command takes the samples we want, we can expand the command to produce the first 3 columns of our sample sheet file in the desired format.

```bash
# generate headers
echo "order","dart_id","id_clean","Genus","Species","Longitude","Latitude","Locality" > individuals.csv

# append output of command below on to the `individuals.csv` file
awk -F, '{ if ( $11 ~ /yes/ ) { gsub(/ /,"_");\
print $8"," $9","toupper(substr($3,1,1))toupper(substr($4,1,2))"-"$2"-"$9","\
$3","$4","$7","$6","$5 } }' atm_genetic_dataset.csv >> individuals.csv
```

Preview our `individuals.csv`:
|order       |dart_id|id_clean                  |Genus    |Species       |Longitude  |Latitude    |Locality    |
|------------|-------|--------------------------|---------|--------------|-----------|------------|------------|
|DNote21-6332|2562202|AAP-Aaprae_4.12.01-2562202|Aipysurus|apraefrontalis|123.04166  |-12.24174549|Ashmore_Reef|
|DNote21-6332|2562130|AAP-KLS0834-2562130       |Aipysurus|apraefrontalis|114.2999988|-22.166666  |Exmouth_Gulf|
|DNote21-6332|2562139|AAP-SS171013-03-2562139   |Aipysurus|apraefrontalis|118.220874 |-19.6889305 |Pilbara     |
|DNote21-6332|2562140|AFO-Afo1-2562140          |Aipysurus|foliosquama   |123.04166  |-12.24174549|Ashmore_Reef|
|DNote21-6332|2562249|AFO-Afo8-2562249          |Aipysurus|foliosquama   |123.04166  |-12.24174549|Ashmore_Reef|
|DNote21-6332|2571080|AFO-Afo8-2571080          |Aipysurus|foliosquama   |123.04166  |-12.24174549|Ashmore_Reef|
|DNote21-6332|2562167|AFO-SS171014-02-2562167   |Aipysurus|foliosquama   |117.8305545|-19.709453  |Pilbara     |
|DNote23-8556|3517861|AAP-KLS1484-3517861       |Aipysurus|apraefrontalis|114.2999988|-22.166666  |Exmouth_Gulf|
|DNote23-8556|3517868|AAP-KLS1486-3517868       |Aipysurus|apraefrontalis|114.2999988|-22.166666  |Exmouth_Gulf|
|DNote23-8556|3517879|AAP-KLS1490-3517879       |Aipysurus|apraefrontalis|114.2999988|-22.166666  |Exmouth_Gulf|
|Dnote23-8773|3593375|AAP-KLS1435-3593375       |Aipysurus|apraefrontalis|114.20917  |-22.10533   |Exmouth_Gulf|
|Dnote23-8773|3593362|AAP-KLS1436-3593362       |Aipysurus|apraefrontalis|114.321    |-22.120333  |Exmouth_Gulf|
|Dnote23-8773|3593372|AAP-KLS1454-3593372       |Aipysurus|apraefrontalis|114.134833 |-22.1245    |Exmouth_Gulf|
|Dnote23-8773|3593394|AAP-KLS1457-3593394       |Aipysurus|apraefrontalis|114.13483  |-22.1245    |Exmouth_Gulf|
|Dnote23-8773|3593395|AAP-KLS1459-3593395       |Aipysurus|apraefrontalis|114.2005   |-22.134833  |Exmouth_Gulf|
|Dnote23-8773|3593393|AAP-KLS1465-3593393       |Aipysurus|apraefrontalis|114.2999988|-22.166666  |Exmouth_Gulf|
|Dnote23-8773|3593397|AAP-KLS1468-3593397       |Aipysurus|apraefrontalis|114.246667 |-22.090333  |Exmouth_Gulf|
|Dnote23-8773|3593356|AAP-KLS1477-3593356       |Aipysurus|apraefrontalis|114.2999988|-22.166666  |Exmouth_Gulf|
|Dnote23-8773|3593337|AAP-KLS1509-3593337       |Aipysurus|apraefrontalis|114.2999988|-22.166666  |Exmouth_Gulf|
|Dnote23-8773|3593377|AFO-KLS1202-3593377       |Aipysurus|foliosquama   |118.288886 |-20.050212  |Pilbara     |
|DNote24-9763|4013436|AFO-KLS1696-4013436       |Aipysurus|foliosquama   |113.4100415|-25.24705   |Shark_Bay   |
|DNote24-9763|4013440|AFO-KLS1700-4013440       |Aipysurus|foliosquama   |113.1631085|-25.623425  |Shark_Bay   |
|DNote24-9763|4013441|AFO-KLS1701-4013441       |Aipysurus|foliosquama   |113.1631085|-25.623425  |Shark_Bay   |
|DNote24-9763|4013442|AFO-KLS1702-4013442       |Aipysurus|foliosquama   |113.2126165|-25.5985585 |Shark_Bay   |
|DNote24-9763|4013447|AFO-KLS1707-4013447       |Aipysurus|foliosquama   |113.336883 |-25.020975  |Shark_Bay   |
|DNote24-9763|4013448|AFO-KLS1708-4013448       |Aipysurus|foliosquama   |113.2711835|-24.926183  |Shark_Bay   |
|DNote24-9763|4013450|AFO-KLS1710-4013450       |Aipysurus|foliosquama   |113.19455  |-24.9617915 |Shark_Bay   |

We will add the `barcode9l` and `barcode` columns in the next steps.<br>
<br>

#### 3) Extract `barcode9l`,`barcode` information from DArTseq targets file
Each DArTseq order comes with a `targets_*.csv` file. This file has `barcode9l` and `barcode` columns which are additional bases appended specifically to each sample during the RAD sequencing protocol. We need to determine these barcodes to get raw sequences into usable form.

From our `individuals.csv` so far, we know the DArTseq order information. Taking the last for digits we have: `6332`,`8556`,`8773`, and `9763`. We will look into the targets file of these orders which are stored in `PhoenixHPC:/uofaresstor/sanders_lab/sequencing-datasets/radseq/`.<br>

To avoid any accidental/unwanted modifications to original files in the HPC server line (which are irreversible), let us download the `target_*.csv` files specific to each order from the Phoenix HPC into our local machine.<br>

```bash
rsync -at a1235304@p2-log-1.hpc.adelaide.edu.au:/uofaresstor/sanders_lab/sequencing-datasets/radseq/DaRT-DNote21-6332/targets_HLCFMDRXY_1.csv ./6332/
rsync -at a1235304@p2-log-1.hpc.adelaide.edu.au:/uofaresstor/sanders_lab/sequencing-datasets/radseq/DaRT-DNote23-8556/targets_HGHTWDRX3_1.csv ./8556/
rsync -at a1235304@p2-log-1.hpc.adelaide.edu.au:/uofaresstor/sanders_lab/sequencing-datasets/radseq/DaRT-DNote23-8773/targets_22FFK7LT3_2.csv ./8773/
rsync -at a1235304@p2-log-1.hpc.adelaide.edu.au:/uofaresstor/sanders_lab/sequencing-datasets/radseq/DaRT-DNote24-9763/targets_22* ./9763/
```

The commands above copied the `targets_*.csv` file from the relevant `DaRT-DNote##-##` directory into individual directories in our local machine corresponding to the last 4 digits of the order ID. (`6332`,`8556`,`8773`,`9763`).<br>

Now we can use our existing `individuals.csv` and the `targets_*.csv` files we downloaded to get the relevant `barcode9l` and `barcode` information.<br>

We use the following command to do so:
```bash
# generate column headers for `barcodes.csv`
echo targetid,barcode9l,barcode > barcodes.csv

# main for-loop
for i in $(awk -F, '{print $2}' individuals.csv | tail -n +2); 
    do awk -F, '$1==dart_id {print $1","$15","$16}' dart_id="$i" ./*/*.csv; 
        done >> barcodes.csv
```
The first part of the command just above lists the values in `dart_id` column of our `individuals.csv` file.<br>

The next part uses this list by going through each value and finding a match in the first column of the downloaded `targets_*.csv` files. It searches through each of the `targets_*.csv` files in each of the order directories and, if it finds a match, prints the `targetid` (i.e., `dart_id`), the `barcode9l`, and `barcode` columns (columns 15 and 16 in `targets_*.csv`).<br>

The output is then written as `barcodes.csv`

Preview `barcodes.csv`:
|targetid|barcode9l      |barcode       |
|--------|---------------|--------------|
|2562202 |TACCGCTCCATATTG|TACCGCTCCATAT |
|2562130 |ACACTTCGTTCTTGC|ACACTTCGTTCT  |
|2562139 |TCTTCCTAGGTTGCA|TCTTCCTAGGT   |
|2562140 |CTCTCTCTCTAGTAT|CTCTCTCTCTAGTA|
|2562249 |CTTGTGTGTATGCAG|CTTGTGTGTA    |
|2571080 |TTGGTGCGGCGGATT|TTGGTGCGGCGGAT|
|2562167 |ATGAGTAGTCTAATG|ATGAGTAGTCTAA |
|3517861 |TCGCATAGTGTGCAG|TCGCATAGTG    |
|3517868 |TGCGTATAGGTGCAG|TGCGTATAGG    |
|3517879 |AGGATACATCCTTGC|AGGATACATCCT  |
|3593375 |TATGCTCCACATTGC|TATGCTCCACAT  |
|3593362 |TCTACATCCGCTCTT|TCTACATCCGCTCT|
|3593372 |CCGTGAGGTCACCGT|CCGTGAGGTCACCG|
|3593394 |GCCTGCTATGCGGAT|GCCTGCTATGCGGA|
|3593395 |TACAATGTGCGTAAT|TACAATGTGCGTAA|
|3593393 |ATCTCCACCTATTGC|ATCTCCACCTAT  |
|3593397 |CGGACTTCTCGGAGT|CGGACTTCTCGGAG|
|3593356 |AATGTGCCGTCGCTT|AATGTGCCGTCGCT|
|3593337 |TATACAGAGGCTTAT|TATACAGAGGCTTA|
|3593377 |GTCATGGAGTGTGTG|GTCATGGAGTGTG |
|4013436 |ATTACGTCAGTATTG|ATTACGTCAGTAT |
|4013440 |GTCTTAGCAATGCAG|GTCTTAGCAA    |
|4013441 |GAACCGAGGTATGCA|GAACCGAGGTA   |
|4013442 |AAGATCAGGAATGCA|AAGATCAGGAA   |
|4013447 |CTCTAACTATGAGTG|CTCTAACTATGAG |
|4013448 |AACGATGACGTGCAG|AACGATGACG    |
|4013450 |GTGCAGTTCCATGCA|GTGCAGTTCCA   |

I included the `targetid` so I can compare it with the `dart_id` from the `individuals.csv`. This way we can make sure that the information for `barcode9l` and `barcode` are all in line with the same sample.<br>

To check, this command was used: `paste -d, individuals.csv barcodes.csv | awk '{ if ($2 == $4) print "yes" }'` which prints "yes" if `dart_id` ($2) in `individuals.csv` matches with `targetid` in `barcodes.csv` ($4).<br>
<br>

#### 4) Finalise the `sample-sheet.csv` file in the desired format
The goal of this exercise is to generate a sample sheet that follows this format: https://github.com/a-lud/sea-snake-dart/blob/main/data/sample-sheets/240524-sample-linkage.csv<br>

We will now put together the two `.csv` files we have generated: `individuals.csv` and `barcodes.csv`; and finalise our sample sheet.<br>

```bash
paste -d, individuals.csv barcodes.csv |\
awk -F, '{ print $1","$2","$3","$10","$11","$4","$5","$6","$7","$8 }' > sample-sheet.csv
```

Preview `sample-sheet.csv`:
|order       |dart_id|id_clean                  |barcode9l|barcode       |Genus      |Species     |Longitude   |Latitude    |Locality    |
|------------|-------|--------------------------|---------|--------------|-----------|------------|------------|------------|------------|
|DNote21-6332|2562202|AAP-Aaprae_4.12.01-2562202|TACCGCTCCATATTG|TACCGCTCCATAT |Aipysurus  |apraefrontalis|123.04166   |-12.24174549|Ashmore_Reef|
|DNote21-6332|2562130|AAP-KLS0834-2562130       |ACACTTCGTTCTTGC|ACACTTCGTTCT  |Aipysurus  |apraefrontalis|114.2999988 |-22.166666  |Exmouth_Gulf|
|DNote21-6332|2562139|AAP-SS171013-03-2562139   |TCTTCCTAGGTTGCA|TCTTCCTAGGT   |Aipysurus  |apraefrontalis|118.220874  |-19.6889305 |Pilbara     |
|DNote21-6332|2562140|AFO-Afo1-2562140          |CTCTCTCTCTAGTAT|CTCTCTCTCTAGTA|Aipysurus  |foliosquama |123.04166   |-12.24174549|Ashmore_Reef|
|DNote21-6332|2562249|AFO-Afo8-2562249          |CTTGTGTGTATGCAG|CTTGTGTGTA    |Aipysurus  |foliosquama |123.04166   |-12.24174549|Ashmore_Reef|
|DNote21-6332|2571080|AFO-Afo8-2571080          |TTGGTGCGGCGGATT|TTGGTGCGGCGGAT|Aipysurus  |foliosquama |123.04166   |-12.24174549|Ashmore_Reef|
|DNote21-6332|2562167|AFO-SS171014-02-2562167   |ATGAGTAGTCTAATG|ATGAGTAGTCTAA |Aipysurus  |foliosquama |117.8305545 |-19.709453  |Pilbara     |
|DNote23-8556|3517861|AAP-KLS1484-3517861       |TCGCATAGTGTGCAG|TCGCATAGTG    |Aipysurus  |apraefrontalis|114.2999988 |-22.166666  |Exmouth_Gulf|
|DNote23-8556|3517868|AAP-KLS1486-3517868       |TGCGTATAGGTGCAG|TGCGTATAGG    |Aipysurus  |apraefrontalis|114.2999988 |-22.166666  |Exmouth_Gulf|
|DNote23-8556|3517879|AAP-KLS1490-3517879       |AGGATACATCCTTGC|AGGATACATCCT  |Aipysurus  |apraefrontalis|114.2999988 |-22.166666  |Exmouth_Gulf|
|Dnote23-8773|3593375|AAP-KLS1435-3593375       |TATGCTCCACATTGC|TATGCTCCACAT  |Aipysurus  |apraefrontalis|114.20917   |-22.10533   |Exmouth_Gulf|
|Dnote23-8773|3593362|AAP-KLS1436-3593362       |TCTACATCCGCTCTT|TCTACATCCGCTCT|Aipysurus  |apraefrontalis|114.321     |-22.120333  |Exmouth_Gulf|
|Dnote23-8773|3593372|AAP-KLS1454-3593372       |CCGTGAGGTCACCGT|CCGTGAGGTCACCG|Aipysurus  |apraefrontalis|114.134833  |-22.1245    |Exmouth_Gulf|
|Dnote23-8773|3593394|AAP-KLS1457-3593394       |GCCTGCTATGCGGAT|GCCTGCTATGCGGA|Aipysurus  |apraefrontalis|114.13483   |-22.1245    |Exmouth_Gulf|
|Dnote23-8773|3593395|AAP-KLS1459-3593395       |TACAATGTGCGTAAT|TACAATGTGCGTAA|Aipysurus  |apraefrontalis|114.2005    |-22.134833  |Exmouth_Gulf|
|Dnote23-8773|3593393|AAP-KLS1465-3593393       |ATCTCCACCTATTGC|ATCTCCACCTAT  |Aipysurus  |apraefrontalis|114.2999988 |-22.166666  |Exmouth_Gulf|
|Dnote23-8773|3593397|AAP-KLS1468-3593397       |CGGACTTCTCGGAGT|CGGACTTCTCGGAG|Aipysurus  |apraefrontalis|114.246667  |-22.090333  |Exmouth_Gulf|
|Dnote23-8773|3593356|AAP-KLS1477-3593356       |AATGTGCCGTCGCTT|AATGTGCCGTCGCT|Aipysurus  |apraefrontalis|114.2999988 |-22.166666  |Exmouth_Gulf|
|Dnote23-8773|3593337|AAP-KLS1509-3593337       |TATACAGAGGCTTAT|TATACAGAGGCTTA|Aipysurus  |apraefrontalis|114.2999988 |-22.166666  |Exmouth_Gulf|
|Dnote23-8773|3593377|AFO-KLS1202-3593377       |GTCATGGAGTGTGTG|GTCATGGAGTGTG |Aipysurus  |foliosquama |118.288886  |-20.050212  |Pilbara     |
|DNote24-9763|4013436|AFO-KLS1696-4013436       |ATTACGTCAGTATTG|ATTACGTCAGTAT |Aipysurus  |foliosquama |113.4100415 |-25.24705   |Shark_Bay   |
|DNote24-9763|4013440|AFO-KLS1700-4013440       |GTCTTAGCAATGCAG|GTCTTAGCAA    |Aipysurus  |foliosquama |113.1631085 |-25.623425  |Shark_Bay   |
|DNote24-9763|4013441|AFO-KLS1701-4013441       |GAACCGAGGTATGCA|GAACCGAGGTA   |Aipysurus  |foliosquama |113.1631085 |-25.623425  |Shark_Bay   |
|DNote24-9763|4013442|AFO-KLS1702-4013442       |AAGATCAGGAATGCA|AAGATCAGGAA   |Aipysurus  |foliosquama |113.2126165 |-25.5985585 |Shark_Bay   |
|DNote24-9763|4013447|AFO-KLS1707-4013447       |CTCTAACTATGAGTG|CTCTAACTATGAG |Aipysurus  |foliosquama |113.336883  |-25.020975  |Shark_Bay   |
|DNote24-9763|4013448|AFO-KLS1708-4013448       |AACGATGACGTGCAG|AACGATGACG    |Aipysurus  |foliosquama |113.2711835 |-24.926183  |Shark_Bay   |
|DNote24-9763|4013450|AFO-KLS1710-4013450       |GTGCAGTTCCATGCA|GTGCAGTTCCA   |Aipysurus  |foliosquama |113.19455   |-24.9617915 |Shark_Bay   |

We can use now use this file as input in the genomics workflow (see https://github.com/a-lud/sea-snake-dart/tree/main) or begin with `01_rename_batch.sh` in this repository.<br>
<br>

[Back to top](#outline)

---

### On `kraken2` and UniVec databases

Before running `02_qc.sh`, make sure to download:
* latest `kraken2` standard database, and
* UniVec fasta file

#### 1) Download the latest `kraken2` standard database
Download the database from: https://benlangmead.github.io/aws-indexes/k2<br>
<br>
Under Collection > Standard, copy URL link of `tar.gz` file and run the following:
```bash
wget https://genome-idx.s3.amazonaws.com/kraken/k2_standard_20241228.tar.gz
tar -zxvf k2_standard_20241228.tar.gz -C k2_standard_20241228 # make sure the value supplied for `-C` exists
# Command just above should output the files in the directory name supplied.
```
Check for file integrity:
```bash
wget https://genome-idx.s3.amazonaws.com/kraken/standard_20241228/standard.md5
md5sum -c standard.md5 # run where the extracted files are located
```

#### 2) Download the UniVec fasta file
The UniVec fasta file can be downloaded from the NCBI database:
```bash
wget -O univec.fasta https://ftp.ncbi.nlm.nih.gov/pub/UniVec/UniVec
```

Proceed with running `02_qc.sh`. However, be aware that in some instances the `kraken2` step in `02_qc.sh` will output a `fastq` file in the incorrect format resulting in an empty `fastq` file at the end of the script run. This error is still being troubleshooted.</i>
<br>

[Back to top](#outline)

---

### Running `ipyrad`

Originally went with `pixi` package manager to run scripts. But issues with `ipyrad` steps (e.g. 3 to 7) were persistent so I had to uninstall `pixi` and run `ipyrad` via `Anaconda`. See Troubleshoot note below.<br>

#### <i>Troubleshooting note</i>:

>For some reason, running `ipyrad` steps 3 through 7 under `denovo` assembly method encounters an error. This issue does not occur when supplying a reference genome (`reference ## [5] assembly_method`). ALud suspects the issue is with `pixi`. So I uninstalled `pixi` and removed all packages installed with it using commands below:
>```
>rm ~/.pixi/bin/pixi # removes binaries
>rm -r ~/.pixi # removes installed packages
>```
>Then I commented out the lines associated with `pixi` and `Anaconda` in my `~/.bashrc` file. I also removed the existing `ipyrad` conda environment that failed to install just to reset.<br>
><br>
>I restarted Phoenix to apply changes and then ran the commands:
>```
>conda init
>conda create -n ipyrad
>conda activate ipyrad
>conda install ipyrad -c conda-forge -c bioconda
>```

With that out of the way, let us actually run `ipyrad`:
```
# Step 1: Run steps 1 and 2 on all data
ipyrad -p params-all_samples_stringent-s12.txt -s 12

# Step 2: Create two branches - reference and denovo
ipyrad -p params-all_samples_stringent-s12.txt -b AFO-denovo AFO-samples.txt
ipyrad -p params-all_samples_stringent-s12.txt -b AFO-reference AFO-samples.txt

# Step 3: Edit the two new params files 
> Edit denovo argument in params-AFO-denovo.txt <
> Edit reference argument in params-AFO-reference.txt <

# Step 4: Run the remaining steps for each branch
ipyrad -p params-AFO-denovo.txt -s 34567
ipyrad -p params-AFO-reference.txt -s 34567
```
Can then repeat from step 2 for <i>A. apraefrontalis</i> (e.g. `...-b AAP-denovo AAP-samples.txt` and so on).<br>
<br>

After running these commands, the VCF files and other output will be stored in one of the following directories:
* `AFO-denovo_outfiles`
* `AFO-reference_outfiles`
* `AAP-denovo_outfiles`
* `AAP-reference_outfiles`

[Back to top](#outline)

---

### Running `API: ipyrad analysis tools`

><i>The ipyrad-analysis toolkit is a Python interface for taking the output files produced in a ipyrad assembly and running a suite of evolutionary analysis tools with convenient features for filtering for missing data, grouping individuals into populations, dropping samples, and more.</i> [https://ipyrad.readthedocs.io/en/master/API-analysis/index.html]

<i>Last updated: 28 April 2025</i>